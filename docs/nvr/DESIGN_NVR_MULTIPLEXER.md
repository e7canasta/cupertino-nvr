# NVR Multiplexer Architecture Design
**Distributed Video Processing & Visualization System**

> *"El diablo sabe por diablo, no por viejo"* - Dise√±o pragm√°tico para NVR de IA
>
> **Versi√≥n:** 1.0  
> **Fecha:** 2025-10-25  
> **Autores:** Visiona Team  

---

## üéØ Executive Summary

Dise√±o de sistema NVR (Network Video Recorder) moderno con IA que **separa procesamiento de visualizaci√≥n** mediante arquitectura distribuida basada en MQTT pub/sub.

### Problema a Resolver

**Actualmente** (`multiplexer_demo.py` y `multiplexer_pipeline_clean.py`):
- Procesamiento e inference acoplados a visualizaci√≥n
- No se puede escalar horizontalmente (1 proceso = N streams + GUI)
- Overhead de rendering (10-15% CPU) aunque no se necesite visualizaci√≥n
- Imposible tener m√∫ltiples viewers de mismos streams
- Dif√≠cil debugging (todo en un solo proceso)

**Soluci√≥n propuesta**:
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         MQTT          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  StreamProcessor    ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>  ‚îÇ   VideoWall         ‚îÇ
‚îÇ  (Headless)         ‚îÇ  Detection Events     ‚îÇ   (Viewer)          ‚îÇ
‚îÇ                     ‚îÇ                       ‚îÇ                     ‚îÇ
‚îÇ  - RTSP decode      ‚îÇ                       ‚îÇ  - RTSP decode      ‚îÇ
‚îÇ  - Inference        ‚îÇ                       ‚îÇ  - Event listening  ‚îÇ
‚îÇ  - MQTT publish     ‚îÇ                       ‚îÇ  - Render boxes     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Bounded Contexts (DDD)

| Context | Responsabilidad | Deployment |
|---------|----------------|------------|
| **StreamProcessor** | Inference + Event publishing | Headless server (CPU/GPU) |
| **VideoWall** | Visualization + Event consumption | Desktop/Browser |
| **EventBus** | Detection event routing (MQTT) | Broker (mosquitto) |

### Quick Win Strategy

‚úÖ **Phase 1** (MVP - Este dise√±o):
- StreamProcessor: Pipeline headless + MQTT sink
- VideoWall: Multiplexer viewer + MQTT listener
- Protocolo de eventos simple (JSON)

üîÑ **Phase 2** (Futuro):
- Event store (time series DB)
- Web UI viewer (WebRTC)
- Multi-tenant support

---

## üìê Architecture Overview

### System Context

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          NVR IA System                               ‚îÇ
‚îÇ                                                                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ
‚îÇ  ‚îÇ   Camera 1   ‚îÇ    ‚îÇ   Camera 2   ‚îÇ    ‚îÇ   Camera N   ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ  (RTSP src)  ‚îÇ    ‚îÇ  (RTSP src)  ‚îÇ    ‚îÇ  (RTSP src)  ‚îÇ          ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ
‚îÇ         ‚îÇ                   ‚îÇ                   ‚îÇ                   ‚îÇ
‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                   ‚îÇ
‚îÇ                             ‚îÇ                                        ‚îÇ
‚îÇ                             ‚ñº                                        ‚îÇ
‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                        ‚îÇ
‚îÇ              ‚îÇ   StreamProcessor (N=12)     ‚îÇ                        ‚îÇ
‚îÇ              ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ                        ‚îÇ
‚îÇ              ‚îÇ   ‚îÇ InferencePipeline    ‚îÇ   ‚îÇ                        ‚îÇ
‚îÇ              ‚îÇ   ‚îÇ  - VideoSource x12   ‚îÇ   ‚îÇ                        ‚îÇ
‚îÇ              ‚îÇ   ‚îÇ  - YOLO Model        ‚îÇ   ‚îÇ                        ‚îÇ
‚îÇ              ‚îÇ   ‚îÇ  - MQTT Sink         ‚îÇ   ‚îÇ                        ‚îÇ
‚îÇ              ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ                        ‚îÇ
‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                        ‚îÇ
‚îÇ                             ‚îÇ                                        ‚îÇ
‚îÇ                             ‚ñº                                        ‚îÇ
‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                        ‚îÇ
‚îÇ              ‚îÇ   MQTT Broker                ‚îÇ                        ‚îÇ
‚îÇ              ‚îÇ   Topic: nvr/detections/#    ‚îÇ                        ‚îÇ
‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                        ‚îÇ
‚îÇ                             ‚îÇ                                        ‚îÇ
‚îÇ                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                              ‚îÇ
‚îÇ                   ‚îÇ                   ‚îÇ                              ‚îÇ
‚îÇ                   ‚ñº                   ‚ñº                              ‚îÇ
‚îÇ       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îÇ
‚îÇ       ‚îÇ  VideoWall       ‚îÇ  ‚îÇ  EventLogger     ‚îÇ                    ‚îÇ
‚îÇ       ‚îÇ  (OpenCV GUI)    ‚îÇ  ‚îÇ  (Optional)      ‚îÇ                    ‚îÇ
‚îÇ       ‚îÇ  - Render 4x3    ‚îÇ  ‚îÇ  - Store events  ‚îÇ                    ‚îÇ
‚îÇ       ‚îÇ  - Draw boxes    ‚îÇ  ‚îÇ  - Analytics     ‚îÇ                    ‚îÇ
‚îÇ       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îÇ
‚îÇ                                                                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Component Boundaries

```python
# Bounded Context 1: Stream Processing (inference/core/interfaces/nvr/processor/)
‚îú‚îÄ‚îÄ processor.py         # Main headless pipeline
‚îú‚îÄ‚îÄ mqtt_sink.py         # Detection event publisher
‚îî‚îÄ‚îÄ config.py            # Processor configuration

# Bounded Context 2: Visualization (inference/core/interfaces/nvr/wall/)
‚îú‚îÄ‚îÄ wall.py              # Video wall viewer
‚îú‚îÄ‚îÄ mqtt_listener.py     # Event subscriber
‚îú‚îÄ‚îÄ renderer.py          # Detection overlay renderer
‚îî‚îÄ‚îÄ config.py            # Wall configuration

# Bounded Context 3: Event Protocol (inference/core/interfaces/nvr/events/)
‚îú‚îÄ‚îÄ schema.py            # Detection event schema (Pydantic)
‚îî‚îÄ‚îÄ protocol.py          # MQTT topic structure
```

---

## üèóÔ∏è Component Design

### 1. StreamProcessor (Headless Inference Pipeline)

**Responsabilidad**: Procesar streams RTSP y publicar detecciones v√≠a MQTT

#### Architecture

```python
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ StreamProcessor                                                 ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ InferencePipeline                                       ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  video_reference = [stream_1, ..., stream_N]           ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  model_id = "yolov8x-640"                              ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  on_prediction = mqtt_detection_sink                   ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                        ‚îÇ                                        ‚îÇ
‚îÇ                        ‚ñº                                        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ MQTTDetectionSink                                       ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                                                         ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  def on_prediction(predictions, video_frames):         ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ      for pred, frame in zip(predictions, video_frames):‚îÇ    ‚îÇ
‚îÇ  ‚îÇ          event = DetectionEvent(                       ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ              source_id=frame.source_id,                ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ              timestamp=frame.frame_timestamp,          ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ              detections=pred['predictions'],           ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ          )                                              ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ          topic = f"nvr/detections/{frame.source_id}"   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ          mqtt_client.publish(topic, event.json())      ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### Key Design Decisions

‚úÖ **Usar InferencePipeline existente** (no reinventar la rueda)
- ‚úì Multiplexing ya resuelto
- ‚úì Reconnection logic incluida
- ‚úì Watchdog y health monitoring
- ‚úì Model loading optimizado

‚úÖ **Sink es stateless** (KISS principle)
- ‚úì No cache de eventos
- ‚úì Fire-and-forget publishing (QoS 0 por defecto)
- ‚úì F√°cil testing (solo mock MQTT client)

‚úÖ **MQTT over otros protocolos**
- ‚úì Pub/sub nativo (m√∫ltiples consumers)
- ‚úì Topic hierarchy (`nvr/detections/{source_id}`)
- ‚úì Standard en IoT/Industrial
- ‚úì Broker ligero (mosquitto ~5MB RAM)

‚ùå **No hacer**:
- ‚ùå No serializar frames en MQTT (demasiado pesado)
- ‚ùå No almacenar eventos en memoria (memory leak)
- ‚ùå No esperar ACK por cada publish (latency)

#### Configuration

```python
@dataclass
class StreamProcessorConfig:
    """Configuration for headless stream processor"""
    
    # Stream sources
    stream_uris: List[str]
    model_id: str = "yolov8x-640"
    
    # MQTT configuration
    mqtt_host: str = "localhost"
    mqtt_port: int = 1883
    mqtt_topic_prefix: str = "nvr/detections"
    mqtt_qos: int = 0  # Fire-and-forget
    mqtt_username: Optional[str] = None
    mqtt_password: Optional[str] = None
    
    # Pipeline configuration
    max_fps: Optional[float] = None
    confidence_threshold: float = 0.5
    
    # Watchdog
    enable_watchdog: bool = True
```

#### Usage

```python
from inference.core.interfaces.nvr.processor import StreamProcessor

# Configure
config = StreamProcessorConfig(
    stream_uris=[f"rtsp://localhost:8554/live/{i}.stream" for i in range(12)],
    model_id="yolov8x-640",
    mqtt_host="localhost",
    mqtt_port=1883,
)

# Run
processor = StreamProcessor(config)
processor.start()
processor.join()  # Blocks until stopped
```

---

### 2. VideoWall (Event-Driven Viewer)

**Responsabilidad**: Mostrar streams RTSP + overlay de detecciones recibidas v√≠a MQTT

#### Architecture

```python
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ VideoWall                                                       ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ VideoSource Multiplexer (No Inference)                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  cameras = [VideoSource(uri) for uri in stream_uris]   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  frames = multiplex_videos(cameras)                    ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                        ‚îÇ                                        ‚îÇ
‚îÇ                        ‚ñº                                        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ DetectionCache (Thread-Safe)                           ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                                                         ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  cache: Dict[int, DetectionEvent] = {}                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                                                         ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  def update(source_id, event):                         ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ      with lock:                                        ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ          cache[source_id] = event                      ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                                                         ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  def get(source_id) -> Optional[DetectionEvent]:       ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ      with lock:                                        ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ          return cache.get(source_id)                   ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                       ‚îÇ                                         ‚îÇ
‚îÇ                       ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ                       ‚îÇ  ‚îÇ MQTT Listener (Thread)       ‚îÇ      ‚îÇ
‚îÇ                       ‚îÇ  ‚îÇ                               ‚îÇ      ‚îÇ
‚îÇ                       ‚îÇ‚óÑ‚îÄ‚î§ def on_message(topic, payload):‚îÇ    ‚îÇ
‚îÇ                       ‚îÇ  ‚îÇ   event = parse(payload)      ‚îÇ      ‚îÇ
‚îÇ                       ‚îÇ  ‚îÇ   cache.update(event)         ‚îÇ      ‚îÇ
‚îÇ                       ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îÇ                       ‚îÇ                                         ‚îÇ
‚îÇ                       ‚ñº                                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ Renderer                                                ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                                                         ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  for frames in multiplexer:                            ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ      for frame in frames:                              ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ          event = cache.get(frame.source_id)            ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ          if event and not expired(event):              ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ              frame = draw_boxes(frame, event)          ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ          tiles.append(frame)                           ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ      display(tiles)                                    ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### Key Design Decisions

‚úÖ **VideoWall NO hace inference** (separaci√≥n de concerns)
- ‚úì Solo consume eventos MQTT
- ‚úì M√°s ligero (no carga modelo)
- ‚úì M√∫ltiples walls pueden ver mismo processor

‚úÖ **DetectionCache con TTL** (pragmatismo)
- ‚úì √öltima detecci√≥n por stream (Dict[source_id, event])
- ‚úì TTL de 1 segundo (evita overlay de detecciones antiguas)
- ‚úì Thread-safe (lock para updates desde MQTT thread)

‚úÖ **Reutilizar multiplex_videos** (no reinventar)
- ‚úì Ya existe en `inference.core.interfaces.camera.utils`
- ‚úì Maneja reconnection, frame sync, etc.

‚úÖ **Reutilizar render_boxes** (o adaptarlo)
- ‚úì Ya dibuja bounding boxes con supervision
- ‚úì Modificar para NO esperar predictions inline
- ‚úì Leer de cache en vez de recibir directo

#### Configuration

```python
@dataclass
class VideoWallConfig:
    """Configuration for video wall viewer"""
    
    # Stream sources (same URIs as processor)
    stream_uris: List[str]
    
    # MQTT configuration
    mqtt_host: str = "localhost"
    mqtt_port: int = 1883
    mqtt_topic_pattern: str = "nvr/detections/#"  # Subscribe to all
    mqtt_username: Optional[str] = None
    mqtt_password: Optional[str] = None
    
    # Display configuration
    tile_size: Tuple[int, int] = (480, 360)
    grid_columns: int = 4
    display_fps: bool = True
    display_latency: bool = True
    
    # Detection overlay
    detection_ttl_seconds: float = 1.0  # Expire old detections
    box_thickness: int = 2
    label_font_scale: float = 0.6
```

#### Usage

```python
from inference.core.interfaces.nvr.wall import VideoWall

# Configure
config = VideoWallConfig(
    stream_uris=[f"rtsp://localhost:8554/live/{i}.stream" for i in range(12)],
    mqtt_host="localhost",
    mqtt_port=1883,
    tile_size=(480, 360),
)

# Run
wall = VideoWall(config)
wall.start()  # Blocks, shows OpenCV window
```

---

### 3. Event Protocol (MQTT Messages)

**Responsabilidad**: Schema y serializaci√≥n de eventos de detecci√≥n

#### DetectionEvent Schema

```python
from pydantic import BaseModel, Field
from typing import List, Optional
from datetime import datetime

class BoundingBox(BaseModel):
    """Bounding box coordinates (normalized or absolute)"""
    x: float = Field(description="Top-left X coordinate")
    y: float = Field(description="Top-left Y coordinate")
    width: float = Field(description="Box width")
    height: float = Field(description="Box height")

class Detection(BaseModel):
    """Single object detection"""
    class_name: str = Field(description="Detected class")
    confidence: float = Field(ge=0.0, le=1.0, description="Detection confidence")
    bbox: BoundingBox = Field(description="Bounding box")
    tracker_id: Optional[int] = Field(default=None, description="Tracking ID if available")

class DetectionEvent(BaseModel):
    """Detection event published to MQTT"""
    
    # Metadata
    source_id: int = Field(description="Stream source ID (0-indexed)")
    frame_id: int = Field(description="Frame sequence number")
    timestamp: datetime = Field(description="Frame capture timestamp")
    
    # Inference results
    model_id: str = Field(description="Model used for inference")
    inference_time_ms: float = Field(description="Inference duration in ms")
    detections: List[Detection] = Field(description="List of detections")
    
    # Optional metadata
    fps: Optional[float] = Field(default=None, description="Current FPS")
    latency_ms: Optional[float] = Field(default=None, description="End-to-end latency")
    
    class Config:
        json_schema_extra = {
            "example": {
                "source_id": 0,
                "frame_id": 12345,
                "timestamp": "2025-10-25T10:30:00.123Z",
                "model_id": "yolov8x-640",
                "inference_time_ms": 45.2,
                "detections": [
                    {
                        "class_name": "person",
                        "confidence": 0.92,
                        "bbox": {"x": 100, "y": 150, "width": 80, "height": 200},
                        "tracker_id": 42
                    }
                ],
                "fps": 25.3,
                "latency_ms": 120.5
            }
        }
```

#### MQTT Topic Structure

```
nvr/
‚îú‚îÄ‚îÄ detections/
‚îÇ   ‚îú‚îÄ‚îÄ 0              # Stream 0 detections
‚îÇ   ‚îú‚îÄ‚îÄ 1              # Stream 1 detections
‚îÇ   ‚îú‚îÄ‚îÄ ...
‚îÇ   ‚îî‚îÄ‚îÄ N              # Stream N detections
‚îÇ
‚îú‚îÄ‚îÄ stats/
‚îÇ   ‚îú‚îÄ‚îÄ processor      # Processor health/stats
‚îÇ   ‚îî‚îÄ‚îÄ wall           # Wall viewer stats
‚îÇ
‚îî‚îÄ‚îÄ control/
    ‚îú‚îÄ‚îÄ processor      # Control commands (pause, resume, etc.)
    ‚îî‚îÄ‚îÄ wall           # Wall commands (mute stream, etc.)
```

**Topic naming convention**:
- `nvr/detections/{source_id}` - Detection events (retained=False, QoS=0)
- `nvr/stats/processor` - Processor stats (retained=True, QoS=0)
- `nvr/control/#` - Control plane (retained=False, QoS=1)

**Rationale**:
- ‚úì Hierarchical topics enable selective subscription
- ‚úì Wall puede subscribirse solo a streams de inter√©s
- ‚úì EventLogger puede subscribirse a `nvr/detections/#` (wildcard)
- ‚úì Control plane separado del data plane

---

## üì¶ Package Structure

### Independent Package (Recommended ‚úÖ)

```
cupertino/nvr/
‚îú‚îÄ‚îÄ __init__.py               # Package exports
‚îú‚îÄ‚îÄ README.md                 # Package documentation
‚îú‚îÄ‚îÄ Makefile                  # Development tasks
‚îú‚îÄ‚îÄ pyproject.toml            # Package configuration
‚îÇ
‚îú‚îÄ‚îÄ processor/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ processor.py          # StreamProcessor main class
‚îÇ   ‚îú‚îÄ‚îÄ mqtt_sink.py          # MQTTDetectionSink
‚îÇ   ‚îî‚îÄ‚îÄ config.py             # StreamProcessorConfig
‚îÇ
‚îú‚îÄ‚îÄ wall/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ wall.py               # VideoWall main class
‚îÇ   ‚îú‚îÄ‚îÄ mqtt_listener.py      # MQTT subscriber thread
‚îÇ   ‚îú‚îÄ‚îÄ detection_cache.py    # Thread-safe cache with TTL
‚îÇ   ‚îú‚îÄ‚îÄ renderer.py           # Detection overlay renderer
‚îÇ   ‚îî‚îÄ‚îÄ config.py             # VideoWallConfig
‚îÇ
‚îú‚îÄ‚îÄ events/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ schema.py             # Pydantic event schemas
‚îÇ   ‚îî‚îÄ‚îÄ protocol.py           # MQTT topic utilities
‚îÇ
‚îú‚îÄ‚îÄ cli.py                    # CLI entry point
‚îÇ
‚îî‚îÄ‚îÄ tests/
    ‚îú‚îÄ‚îÄ unit/                 # Unit tests
    ‚îÇ   ‚îú‚îÄ‚îÄ test_events.py
    ‚îÇ   ‚îú‚îÄ‚îÄ test_mqtt_sink.py
    ‚îÇ   ‚îî‚îÄ‚îÄ test_cache.py
    ‚îî‚îÄ‚îÄ integration/          # Integration tests
        ‚îî‚îÄ‚îÄ test_e2e.py
```

**Rationale**:
- ‚úÖ **Independent lifecycle** - Own versioning and releases
- ‚úÖ **Clear ownership** - Cupertino namespace (Visiona project)
- ‚úÖ **Flexible deployment** - Can be packaged separately
- ‚úÖ **Own build system** - Makefile for development tasks
- ‚úÖ **Easy integration** - `pip install cupertino-nvr`
- ‚úÖ **Not tied to Inference** - Uses it as dependency, not part of it

**Installation**:
```bash
# Development mode
cd cupertino/nvr
make install-dev

# Or directly
pip install -e .

# Production
pip install cupertino-nvr
```

**CLI Usage**:
```bash
# Using installed package
cupertino-nvr processor --n 12
cupertino-nvr wall --n 12

# Using Makefile (development)
make run-processor N=12
make run-wall N=12
```

---

## üîß Implementation Plan

### Phase 1: MVP (Este Sprint)

#### 1.1 Event Protocol
```bash
inference/core/interfaces/nvr/events/
‚îú‚îÄ‚îÄ schema.py         # DetectionEvent, BoundingBox, Detection (Pydantic)
‚îî‚îÄ‚îÄ protocol.py       # topic_for_source(id), parse_topic(), etc.
```

**Validation**: Unit tests con pytest
```python
def test_detection_event_serialization():
    event = DetectionEvent(...)
    json_str = event.model_dump_json()
    parsed = DetectionEvent.model_validate_json(json_str)
    assert parsed == event
```

#### 1.2 StreamProcessor
```bash
inference/core/interfaces/nvr/processor/
‚îú‚îÄ‚îÄ config.py         # StreamProcessorConfig
‚îú‚îÄ‚îÄ mqtt_sink.py      # MQTTDetectionSink (sink function)
‚îî‚îÄ‚îÄ processor.py      # StreamProcessor (wrapper around InferencePipeline)
```

**Dependencies**:
- `InferencePipeline` (already exists)
- `paho-mqtt` (already used in enterprise MQTT sink)

**Key code**:
```python
# mqtt_sink.py
class MQTTDetectionSink:
    def __init__(self, mqtt_client, topic_prefix: str, model_id: str):
        self.client = mqtt_client
        self.topic_prefix = topic_prefix
        self.model_id = model_id
    
    def __call__(
        self,
        predictions: Union[dict, List[Optional[dict]]],
        video_frame: Union[VideoFrame, List[Optional[VideoFrame]]],
    ) -> None:
        """Sink compatible with InferencePipeline signature"""
        predictions = wrap_in_list(predictions)
        video_frame = wrap_in_list(video_frame)
        
        for pred, frame in zip(predictions, video_frame):
            if frame is None or pred is None:
                continue
            
            event = self._create_event(pred, frame)
            topic = f"{self.topic_prefix}/{frame.source_id}"
            self.client.publish(topic, event.model_dump_json(), qos=0)
    
    def _create_event(self, prediction: dict, frame: VideoFrame) -> DetectionEvent:
        """Convert Roboflow prediction to DetectionEvent"""
        detections = []
        for p in prediction.get("predictions", []):
            detections.append(Detection(
                class_name=p["class"],
                confidence=p["confidence"],
                bbox=BoundingBox(
                    x=p["x"],
                    y=p["y"],
                    width=p["width"],
                    height=p["height"],
                ),
                tracker_id=p.get("tracker_id"),
            ))
        
        return DetectionEvent(
            source_id=frame.source_id,
            frame_id=frame.frame_id,
            timestamp=frame.frame_timestamp,
            model_id=self.model_id,
            inference_time_ms=prediction.get("time", 0) * 1000,
            detections=detections,
        )
```

**Testing**:
```python
# Mock MQTT client
class MockMQTTClient:
    def __init__(self):
        self.published = []
    
    def publish(self, topic, payload, qos):
        self.published.append((topic, payload, qos))

def test_mqtt_sink_publishes_events():
    client = MockMQTTClient()
    sink = MQTTDetectionSink(client, "nvr/detections", "yolov8x-640")
    
    # Create mock prediction and frame
    prediction = {"predictions": [...]}
    frame = VideoFrame(...)
    
    sink(prediction, frame)
    
    assert len(client.published) == 1
    topic, payload, qos = client.published[0]
    assert topic == "nvr/detections/0"
    event = DetectionEvent.model_validate_json(payload)
    assert event.source_id == 0
```

#### 1.3 VideoWall
```bash
inference/core/interfaces/nvr/wall/
‚îú‚îÄ‚îÄ config.py             # VideoWallConfig
‚îú‚îÄ‚îÄ detection_cache.py    # DetectionCache (thread-safe dict with TTL)
‚îú‚îÄ‚îÄ mqtt_listener.py      # MQTTListener (subscriber thread)
‚îú‚îÄ‚îÄ renderer.py           # render_detections_from_cache()
‚îî‚îÄ‚îÄ wall.py               # VideoWall main class
```

**Key code**:
```python
# detection_cache.py
from threading import Lock
from typing import Dict, Optional
from datetime import datetime, timedelta

class DetectionCache:
    """Thread-safe cache for detection events with TTL"""
    
    def __init__(self, ttl_seconds: float = 1.0):
        self._cache: Dict[int, tuple[DetectionEvent, datetime]] = {}
        self._lock = Lock()
        self._ttl = timedelta(seconds=ttl_seconds)
    
    def update(self, event: DetectionEvent) -> None:
        with self._lock:
            self._cache[event.source_id] = (event, datetime.now())
    
    def get(self, source_id: int) -> Optional[DetectionEvent]:
        with self._lock:
            if source_id not in self._cache:
                return None
            event, timestamp = self._cache[source_id]
            if datetime.now() - timestamp > self._ttl:
                del self._cache[source_id]  # Expired
                return None
            return event
```

```python
# mqtt_listener.py
from threading import Thread
import paho.mqtt.client as mqtt

class MQTTListener(Thread):
    """Background thread for MQTT subscription"""
    
    def __init__(self, config: VideoWallConfig, cache: DetectionCache):
        super().__init__(daemon=True)
        self.config = config
        self.cache = cache
        self.client = mqtt.Client()
        self.client.on_message = self._on_message
    
    def run(self):
        if self.config.mqtt_username:
            self.client.username_pw_set(
                self.config.mqtt_username,
                self.config.mqtt_password
            )
        self.client.connect(self.config.mqtt_host, self.config.mqtt_port)
        self.client.subscribe(self.config.mqtt_topic_pattern)
        self.client.loop_forever()
    
    def _on_message(self, client, userdata, msg):
        try:
            event = DetectionEvent.model_validate_json(msg.payload)
            self.cache.update(event)
        except Exception as e:
            logger.error(f"Failed to parse detection event: {e}")
```

```python
# wall.py
class VideoWall:
    def __init__(self, config: VideoWallConfig):
        self.config = config
        self.cache = DetectionCache(ttl_seconds=config.detection_ttl_seconds)
        self.mqtt_listener = MQTTListener(config, self.cache)
    
    def start(self):
        # Start MQTT listener
        self.mqtt_listener.start()
        
        # Initialize video sources
        cameras = [
            VideoSource.init(uri, source_id=i)
            for i, uri in enumerate(self.config.stream_uris)
        ]
        
        for camera in cameras:
            camera.start()
        
        # Multiplex and render
        multiplexer = multiplex_videos(
            videos=cameras,
            should_stop=lambda: STOP,
        )
        
        for frames in multiplexer:
            self._render_frame_batch(frames)
    
    def _render_frame_batch(self, frames: List[VideoFrame]):
        images = []
        for frame in frames:
            # Get cached detections for this source
            event = self.cache.get(frame.source_id)
            
            # Render frame with detections overlay
            image = self._render_frame_with_detections(frame, event)
            images.append(image)
        
        # Create grid and display
        tiles = create_tiles(images, self.config.grid_columns)
        cv2.imshow("NVR Video Wall", tiles)
        cv2.waitKey(1)
    
    def _render_frame_with_detections(
        self,
        frame: VideoFrame,
        event: Optional[DetectionEvent]
    ) -> np.ndarray:
        """Render frame with detection overlay"""
        image = frame.image.copy()
        
        if event is None:
            return letterbox_image(image, self.config.tile_size)
        
        # Convert detections to supervision format
        detections = self._event_to_sv_detections(event)
        
        # Annotate (reuse supervision annotators)
        image = sv.BoxAnnotator().annotate(image, detections)
        labels = [d.class_name for d in event.detections]
        image = sv.LabelAnnotator().annotate(image, detections, labels)
        
        # Add statistics overlay
        if self.config.display_latency:
            latency_ms = (datetime.now() - event.timestamp).total_seconds() * 1000
            cv2.putText(image, f"Latency: {latency_ms:.0f}ms", ...)
        
        return letterbox_image(image, self.config.tile_size)
```

#### 1.4 CLI Integration
```bash
inference_cli/nvr.py      # New CLI module
```

```python
# inference_cli/nvr.py
import click
from inference.core.interfaces.nvr.processor import StreamProcessor, StreamProcessorConfig
from inference.core.interfaces.nvr.wall import VideoWall, VideoWallConfig

@click.group()
def nvr():
    """Network Video Recorder commands"""
    pass

@nvr.command()
@click.option("--n", type=int, default=6, help="Number of streams")
@click.option("--model", default="yolov8x-640", help="Model ID")
@click.option("--mqtt-host", default="localhost", help="MQTT broker host")
@click.option("--mqtt-port", type=int, default=1883, help="MQTT broker port")
@click.option("--stream-server", default="rtsp://localhost:8554", help="RTSP server URL")
def processor(n, model, mqtt_host, mqtt_port, stream_server):
    """Run headless stream processor"""
    config = StreamProcessorConfig(
        stream_uris=[f"{stream_server}/live/{i}.stream" for i in range(n)],
        model_id=model,
        mqtt_host=mqtt_host,
        mqtt_port=mqtt_port,
    )
    proc = StreamProcessor(config)
    proc.start()
    proc.join()

@nvr.command()
@click.option("--n", type=int, default=6, help="Number of streams")
@click.option("--mqtt-host", default="localhost", help="MQTT broker host")
@click.option("--mqtt-port", type=int, default=1883, help="MQTT broker port")
@click.option("--stream-server", default="rtsp://localhost:8554", help="RTSP server URL")
def wall(n, mqtt_host, mqtt_port, stream_server):
    """Run video wall viewer"""
    config = VideoWallConfig(
        stream_uris=[f"{stream_server}/live/{i}.stream" for i in range(n)],
        mqtt_host=mqtt_host,
        mqtt_port=mqtt_port,
    )
    wall_app = VideoWall(config)
    wall_app.start()
```

**Usage**:
```bash
# Terminal 1: Start processor
inference nvr processor --n 12 --model yolov8x-640

# Terminal 2: Start wall
inference nvr wall --n 12

# Terminal 3: Monitor MQTT (debug)
mosquitto_sub -t "nvr/detections/#" -v
```

---

### Phase 2: Enhancements (Futuro)

#### 2.1 Event Store (Time Series)
- PostgreSQL + TimescaleDB para eventos hist√≥ricos
- Query API: "Dame detecciones de stream 5 entre 10:00-11:00"
- Analytics: heatmaps, dwell time, traffic flow

#### 2.2 Web UI Viewer
- React + WebRTC para streaming
- Multiple layouts (1x1, 2x2, 4x3, custom)
- PTZ controls (si c√°maras lo soportan)

#### 2.3 Multi-Tenant
- MQTT topic: `nvr/{tenant_id}/detections/{source_id}`
- Auth & isolation por tenant
- Quota enforcement

#### 2.4 Advanced Features
- **Person re-identification**: Track across cameras
- **Alert rules**: MQTT publish to `nvr/alerts/{rule_id}`
- **Recording on demand**: Save clips when detections occur
- **Thermal overlays**: Integration with thermal cameras

---

## üé∏ Design Principles (Manifesto Compliance)

### ‚úÖ Bounded Contexts Claros
- **Processor**: Inference domain (model, predictions)
- **Wall**: Visualization domain (rendering, UI)
- **EventBus**: Integration domain (MQTT protocol)

### ‚úÖ Pragmatismo > Purismo
- Reutilizamos `InferencePipeline` (no reimplementamos)
- Usamos `supervision` para rendering (no custom annotators)
- MQTT sin garant√≠as (QoS=0) es suficiente para video en tiempo real

### ‚úÖ KISS ‚â† Simplicidad Ingenua
- DetectionCache tiene TTL (previene memory leaks)
- MQTT listener en thread separado (no bloquea rendering)
- Versioning de eventos (permite evoluci√≥n del protocolo)

### ‚úÖ Dise√±o Evolutivo
- Phase 1 (MVP): Funcional con OpenCV
- Phase 2: Web UI, analytics, multi-tenant
- Extensible sin breaking changes (versioned events)

### ‚úÖ Testing como Feedback
- Unit tests con mocks (MQTT client, VideoFrame)
- Integration tests con mosquitto local
- Property tests para event serialization

---

## üìä Trade-offs Evaluation

### Pros ‚úÖ

| Aspecto | Beneficio |
|---------|-----------|
| **Escalabilidad** | N processors + M walls independientes |
| **Performance** | Wall sin inference = 50% menos CPU |
| **Debugging** | Logs separados, f√°cil troubleshooting |
| **Flexibility** | Wall puede consumir eventos de m√∫ltiples processors |
| **Extensibility** | F√°cil agregar event consumers (logger, analytics) |

### Cons ‚ùå

| Aspecto | Costo |
|---------|-------|
| **Latency** | +50-100ms por hop MQTT (processor ‚Üí broker ‚Üí wall) |
| **Complexity** | +1 dependency (MQTT broker) |
| **Sync issues** | Wall puede perder eventos si MQTT falla |
| **Bandwidth** | MQTT traffic proporcional a detecciones/sec |

### Mitigations üõ°Ô∏è

| Problema | Soluci√≥n |
|----------|----------|
| **MQTT latency** | QoS=0 (fire-and-forget), broker local |
| **Event loss** | Acceptable para real-time video (TTL=1s en wall) |
| **Broker SPOF** | Monitor con watchdog, auto-restart |
| **Bandwidth** | Comprimir payloads (JSON ‚Üí MessagePack opcional) |

---

## üöÄ Success Metrics

### MVP Definition of Done

‚úÖ **Functional**:
- [ ] Processor procesa 12 streams @ 25 FPS sin drops
- [ ] Wall muestra 12 streams con detections overlay
- [ ] End-to-end latency < 200ms (frame capture ‚Üí display)
- [ ] No memory leaks en runs de 1 hora

‚úÖ **Quality**:
- [ ] Test coverage > 80% (events, cache, sink)
- [ ] Integration test con mosquitto + go2rtc
- [ ] CLI funcional (`inference nvr processor/wall`)
- [ ] Documentaci√≥n en README con ejemplos

‚úÖ **Performance**:
- [ ] Processor CPU < 60% en 12 streams (mini PC i5)
- [ ] Wall CPU < 20% (sin inference)
- [ ] MQTT broker RAM < 50MB

---

## üìö References

### Existing Code
- `inference/core/interfaces/stream/sinks.py` - render_boxes, UDPSink
- `inference/core/interfaces/stream/inference_pipeline.py` - InferencePipeline
- `inference/core/interfaces/camera/utils.py` - multiplex_videos
- `inference/enterprise/workflows/enterprise_blocks/sinks/mqtt_writer/v1.py` - MQTT patterns
- `development/stream_interface/multiplexer_demo.py` - Multiplexer sin inference
- `development/stream_interface/multiplexer_pipeline_clean.py` - Multiplexer con inference

### External
- [paho-mqtt](https://github.com/eclipse/paho.mqtt.python) - MQTT client library
- [mosquitto](https://mosquitto.org/) - MQTT broker (5MB Docker image)
- [supervision](https://github.com/roboflow/supervision) - Annotation utilities
- [go2rtc](https://github.com/AlexxIT/go2rtc) - RTSP server for testing

---

## üéØ Next Steps

1. **Review & Feedback** (Ernesto + Visiona Team)
   - ¬øBounded contexts correctos?
   - ¬øPackage structure apropiada (core vs enterprise)?
   - ¬øAlg√∫n concern de seguridad/performance?

2. **Spike: MQTT Latency** (1 d√≠a)
   - Medir latency real con mosquitto local
   - Validar que QoS=0 es suficiente
   - Test con 12 streams @ 25 FPS

3. **Implementation: Phase 1** (1 semana)
   - D√≠a 1-2: Events + MQTTDetectionSink
   - D√≠a 3-4: StreamProcessor + tests
   - D√≠a 5-6: VideoWall + DetectionCache
   - D√≠a 7: Integration test + CLI

4. **Documentation** (paralelo)
   - README en `inference/core/interfaces/nvr/`
   - Actualizar wiki con arquitectura
   - Tutorial en `docs/` con go2rtc setup

---

## üìù Open Questions

1. **¬øUbicaci√≥n del package?**
   - **Opci√≥n A**: `inference/core/interfaces/nvr/` (recomendada)
   - **Opci√≥n B**: `inference/enterprise/nvr/` (si es enterprise-only)

2. **¬øEvent versioning strategy?**
   - **Opci√≥n A**: Topic suffix (`nvr/detections/v1/{source_id}`)
   - **Opci√≥n B**: Payload field (`event.version = "1.0"`)

3. **¬øWall necesita inference capability?**
   - **Ahora**: No (solo consume eventos)
   - **Futuro**: ¬øHybrid mode? (inference local + eventos remotos)

4. **¬øControl plane scope?**
   - **MVP**: Sin control plane (solo data)
   - **Phase 2**: Control topics para pause/resume/restart

5. **¬øIntegration con stream_management existente?**
   - `inference/enterprise/stream_management/` ya existe
   - ¬øNVR deber√≠a usar ese o ser independiente?

---

**üé∏ "El diablo sabe por diablo, no por viejo"**

Este dise√±o prioriza **aprendizaje r√°pido** (MVP funcional en 1 semana) sobre **dise√±o especulativo** (arquitectura perfecta que nunca se usa). Vamos a tocar buen blues con este c√≥digo. üöÄ

**Versi√≥n:** 1.0  
**Estado:** üü° Awaiting Review  
**Pr√≥ximo paso:** Feedback + Spike MQTT latency

---

**Para futuros Claudes:**
Este dise√±o sigue el MANIFESTO - pragm√°tico, evolutivo, con bounded contexts claros. Si vas a implementar Phase 2, lee primero este doc y el MANIFESTO. No sobre-dise√±es, itera basado en feedback real del MVP.

¬°Buen c√≥digo, compa√±eros! üöÄ

