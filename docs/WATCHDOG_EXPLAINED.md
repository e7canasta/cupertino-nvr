# InferencePipeline Watchdog - Qu√© Es y Por Qu√© No Lo Usamos

## Qu√© Es

**Watchdog** es un monitor de observabilidad built-in de InferencePipeline. Recolecta m√©tricas de performance en tiempo real.

### M√©tricas que Recolecta

```python
@dataclass
class PipelineStateReport:
    video_source_status_updates: List[StatusUpdate]  # Errores de conexi√≥n RTSP, etc
    latency_reports: List[LatencyMonitorReport]      # Latencias por stream
    inference_throughput: float                       # FPS del modelo (no de video)
    sources_metadata: List[SourceMetadata]            # Info de streams

@dataclass
class LatencyMonitorReport:
    source_id: int
    frame_decoding_latency: float  # Tiempo de decodificar frame (ms)
    inference_latency: float        # Tiempo de inferencia pura (ms)
    e2e_latency: float              # End-to-end (decode ‚Üí predict) (ms)
```

### C√≥mo Funciona

```python
from inference import InferencePipeline
from inference.core.interfaces.stream.watchdog import BasePipelineWatchDog

# Crear watchdog
watchdog = BasePipelineWatchDog()

# Pasarlo a pipeline
pipeline = InferencePipeline.init(
    video_reference=streams,
    model_id="yolov8x-640",
    on_prediction=sink,
    watchdog=watchdog,  # ‚Üê InferencePipeline lo usa internamente
)

pipeline.start()

# Despu√©s (en cualquier momento)
report = watchdog.get_report()

print(f"FPS de inferencia: {report.inference_throughput}")
print(f"Latencia promedio: {report.latency_reports[0].e2e_latency * 1000} ms")
```

**Internamente, InferencePipeline llama a:**
- `watchdog.on_model_inference_started(frames)` - Antes de inferir
- `watchdog.on_model_prediction_ready(frames)` - Despu√©s de inferir
- `watchdog.on_status_update(status)` - Cuando hay errores RTSP, etc

El watchdog acumula estas m√©tricas en buffers circulares (√∫ltimos 64 frames).

---

## Por Qu√© NO Lo Estamos Usando (Actualmente)

### 1. Lo Habilitamos Pero NO Consultamos

**En nuestro c√≥digo actual:**
```python
# processor/config.py
enable_watchdog: bool = True  # ‚úÖ Habilitado por default

# processor/processor.py
if self.config.enable_watchdog:
    self.watchdog = BasePipelineWatchDog()  # ‚úÖ Se crea

self.pipeline = InferencePipeline.init(
    watchdog=self.watchdog,  # ‚úÖ Se pasa
    ...
)
```

**Problema:** Nunca llamamos `self.watchdog.get_report()` ü§¶

El watchdog est√° recolectando m√©tricas pero **no las usamos para nada**:
- ‚ùå No las logueamos
- ‚ùå No las publicamos via MQTT
- ‚ùå No las exponemos via comando STATUS

**Es como tener un term√≥metro pegado pero nunca mirarlo.**

---

### 2. No Hay Comando METRICS

En Adeline tienen comando `METRICS` que retorna el report del watchdog:

```python
# Adeline
def _handle_metrics(self):
    if self.watchdog:
        report = self.watchdog.get_report()
        # Publish via MQTT
        self.control_plane.publish_metrics(report)
```

**Nosotros NO tenemos esto.** Solo tenemos PAUSE/RESUME/STOP/STATUS.

---

### 3. No Publicamos en DetectionEvent

Podr√≠amos agregar m√©tricas a cada evento de detecci√≥n:

```python
@dataclass
class DetectionEvent:
    source_id: int
    frame_id: int
    detections: List[Detection]
    fps: Optional[float]         # ‚Üê Actualmente None
    latency_ms: Optional[float]  # ‚Üê Actualmente None
```

**Actualmente seteamos estos a None:**
```python
# mqtt_sink.py
return DetectionEvent(
    ...
    fps=None,  # ‚Üê Podr√≠amos obtener de watchdog
    latency_ms=None,  # ‚Üê Podr√≠amos obtener de watchdog
)
```

---

## Por Qu√© DEBER√çAMOS Usarlo

### Use Case 1: Monitoring de Performance

```bash
# Via comando MQTT
mosquitto_pub -t "nvr/control/commands" -m '{"command": "metrics"}'

# Respuesta
{
  "inference_throughput": 28.5,  # FPS de inferencia (no video)
  "latency_reports": [
    {
      "source_id": 0,
      "frame_decoding_latency": 0.015,  # 15ms decode
      "inference_latency": 0.032,        # 32ms inferencia
      "e2e_latency": 0.047               # 47ms total
    }
  ],
  "video_source_status_updates": [
    "RTSP stream 3 reconnecting..."
  ]
}
```

**Beneficio:** Visibility de si el sistema est√° performando bien o tiene bottlenecks.

---

### Use Case 2: Alertas de Degradaci√≥n

```python
# En un loop peri√≥dico (cada 10 segundos)
def _monitor_performance(self):
    report = self.watchdog.get_report()

    # Alert si FPS baja
    if report.inference_throughput < 10:
        logger.warning(f"‚ö†Ô∏è Throughput degraded: {report.inference_throughput} FPS")
        self.control_plane.publish_alert("low_throughput")

    # Alert si latencia sube
    avg_latency = sum(r.e2e_latency for r in report.latency_reports) / len(report.latency_reports)
    if avg_latency > 0.2:  # 200ms
        logger.warning(f"‚ö†Ô∏è High latency: {avg_latency * 1000} ms")
```

**Beneficio:** Detectar problemas antes de que el usuario se queje.

---

### Use Case 3: Debugging de Latencia

Cuando un stream est√° lagueado:

```python
report = self.watchdog.get_report()

for stream_report in report.latency_reports:
    print(f"Stream {stream_report.source_id}:")
    print(f"  Decode: {stream_report.frame_decoding_latency * 1000:.1f} ms")
    print(f"  Inference: {stream_report.inference_latency * 1000:.1f} ms")
    print(f"  Total: {stream_report.e2e_latency * 1000:.1f} ms")
```

**Output:**
```
Stream 0:
  Decode: 15.2 ms
  Inference: 32.1 ms  ‚Üê Bottleneck!
  Total: 47.3 ms

Stream 1:
  Decode: 14.8 ms
  Inference: 180.5 ms  ‚Üê ¬°Problema! Mucho m√°s lento
  Total: 195.3 ms
```

**Beneficio:** Identificar cu√°l stream o qu√© parte (decode vs inference) es el bottleneck.

---

### Use Case 4: Incluir M√©tricas en Eventos

```python
class MQTTDetectionSink:
    def __init__(self, mqtt_client, watchdog):
        self.watchdog = watchdog  # ‚Üê Pasar watchdog

    def __call__(self, predictions, video_frame):
        # Obtener m√©tricas actuales
        report = self.watchdog.get_report() if self.watchdog else None

        fps = report.inference_throughput if report else None
        latency_ms = None
        if report:
            # Buscar latencia del stream actual
            for r in report.latency_reports:
                if r.source_id == video_frame.source_id:
                    latency_ms = r.e2e_latency * 1000
                    break

        event = DetectionEvent(
            ...
            fps=fps,           # ‚Üê Ahora tiene valor!
            latency_ms=latency_ms,  # ‚Üê Ahora tiene valor!
        )
```

**Beneficio:** Cada evento MQTT incluye m√©tricas de performance. √ötil para dashboards.

---

## C√≥mo Deber√≠amos Usarlo

### Opci√≥n 1: Comando METRICS (Recomendado)

```python
# En processor.py
def _setup_control_commands(self):
    registry.register('pause', self._handle_pause)
    registry.register('resume', self._handle_resume)
    registry.register('stop', self._handle_stop)
    registry.register('status', self._handle_status)
    registry.register('metrics', self._handle_metrics)  # ‚Üê Nuevo

def _handle_metrics(self):
    """Handle METRICS command"""
    if self.watchdog:
        report = self.watchdog.get_report()

        # Serializar a dict
        metrics = {
            "inference_throughput": report.inference_throughput,
            "latency_reports": [
                {
                    "source_id": r.source_id,
                    "frame_decoding_latency_ms": r.frame_decoding_latency * 1000 if r.frame_decoding_latency else None,
                    "inference_latency_ms": r.inference_latency * 1000 if r.inference_latency else None,
                    "e2e_latency_ms": r.e2e_latency * 1000 if r.e2e_latency else None,
                }
                for r in report.latency_reports
            ],
            "sources": [
                {"source_id": m.source_id, "fps": m.fps, "resolution": f"{m.width}x{m.height}"}
                for m in report.sources_metadata
            ],
            "errors": [
                {"source_id": u.source_id, "message": u.payload["message"]}
                for u in report.video_source_status_updates
                if u.severity == UpdateSeverity.ERROR
            ]
        }

        # Publicar via MQTT
        self.control_plane.publish(
            topic=f"{self.config.control_status_topic}/metrics",
            payload=json.dumps(metrics),
            qos=0,
            retain=False
        )

        logger.info("üìä Metrics published", extra={"metrics": metrics})
    else:
        logger.warning("‚ö†Ô∏è Watchdog not enabled")
```

**Uso:**
```bash
# Query metrics
mosquitto_pub -t "nvr/control/commands" -m '{"command": "metrics"}'

# Monitor metrics
mosquitto_sub -t "nvr/control/status/metrics"
```

---

### Opci√≥n 2: Logging Peri√≥dico

```python
# En processor.py
def start(self):
    # ... setup normal ...

    # Start metrics logging thread
    if self.watchdog:
        self._start_metrics_logging()

def _start_metrics_logging(self):
    """Log metrics every 10 seconds"""
    import threading
    import time

    def log_metrics():
        while self.is_running:
            time.sleep(10)

            if not self.is_running:
                break

            report = self.watchdog.get_report()
            logger.info(
                f"üìä Performance Metrics",
                extra={
                    "component": "processor",
                    "event": "metrics_snapshot",
                    "inference_throughput": report.inference_throughput,
                    "avg_latency_ms": sum(
                        r.e2e_latency * 1000 for r in report.latency_reports
                    ) / len(report.latency_reports) if report.latency_reports else None,
                }
            )

    thread = threading.Thread(target=log_metrics, daemon=True)
    thread.start()
```

**Beneficio:** Logs autom√°ticos sin necesidad de query MQTT. √ötil para debugging.

---

### Opci√≥n 3: Incluir en DetectionEvent (M√°s Overhead)

Ver "Use Case 4" arriba.

**Trade-off:**
- ‚úÖ M√©tricas en cada evento (√∫til para dashboards)
- ‚ùå Overhead de llamar `get_report()` en cada frame (~microsegundos)
- ‚ùå MQTT payloads m√°s grandes

**Recomendaci√≥n:** NO hacer esto. Usar comando METRICS es mejor.

---

## Comparaci√≥n con Adeline

| Feature | Cupertino NVR (Actual) | Adeline | Recomendaci√≥n |
|---------|------------------------|---------|---------------|
| Watchdog habilitado | ‚úÖ | ‚úÖ | ‚úÖ Keep |
| Comando METRICS | ‚ùå | ‚úÖ | ‚úÖ Implementar |
| Logging peri√≥dico | ‚ùå | ‚úÖ | ‚úÖ Implementar |
| M√©tricas en eventos | ‚ùå | ‚ùå | ‚ùå No necesario |
| Alert de degradaci√≥n | ‚ùå | ‚ö†Ô∏è B√°sico | üü° Considerar |

---

## Recomendaci√≥n Final

### Quick Win 1: Comando METRICS (30 minutos)

Implementar `_handle_metrics()` para exponer watchdog data via MQTT.

**Beneficio:** Visibility inmediata de performance sin cambios mayores.

**Complejidad:** Baja (solo agregar handler + serializaci√≥n)

---

### Quick Win 2: Logging Peri√≥dico (15 minutos)

Log autom√°tico de m√©tricas cada 10-30 segundos.

**Beneficio:** Debugging m√°s f√°cil (m√©tricas en logs)

**Complejidad:** Muy baja (thread daemon simple)

---

### Future Enhancement: Alertas (1-2 horas)

Monitor de degradaci√≥n con thresholds configurables.

**Beneficio:** Detectar problemas proactivamente

**Complejidad:** Media (necesita config de thresholds + l√≥gica de alertas)

---

## Conclusi√≥n

**Pregunta de Ernesto:** "¬øPor qu√© no lo usamos?"

**Respuesta:** Lo habilitamos pero nunca consultamos. Es como tener un speedometer pero nunca mirar.

**Acci√≥n recomendada:**
1. Implementar comando METRICS (quick win)
2. Agregar logging peri√≥dico (quick win)
3. Considerar alertas despu√©s (si hay necesidad)

**ROI:**
- Tiempo: 45 minutos (ambos quick wins)
- Beneficio: Visibility de performance + debugging m√°s f√°cil
- Sin impacto en performance existente (watchdog ya est√° corriendo)

---

**Filosof√≠a Blues:** "El watchdog ya est√° tocando, solo necesitamos escuchar" üé∏

---

*Documentado: 2025-10-25*
*Para: cupertino-nvr*
